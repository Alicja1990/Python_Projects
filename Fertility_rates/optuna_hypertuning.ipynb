{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold, cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gender_stats_preprocessed.csv\")\n",
    "df = df.dropna(axis=1)\n",
    "x = df.drop(columns=['Country Name'], axis=0)\n",
    "x = x.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_scaled = pd.DataFrame(x_scaled, columns=df.columns[1:], index=df['Country Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_scaled, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Poland\" not in test_data.index:\n",
    "    test_data.loc['Poland'] = train_data.loc['Poland']\n",
    "    train_data.drop('Poland', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['Fertility rate, total (births per woman)'].copy()\n",
    "X_train = train_data.drop('Fertility rate, total (births per woman)', axis=1)\n",
    "\n",
    "y_test = test_data['Fertility rate, total (births per woman)'].copy()\n",
    "X_test = test_data.drop('Fertility rate, total (births per woman)', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    units_first_layer = trial.suggest_int(\"units_first_layer\", 10, 100)\n",
    "    units_second_layer = trial.suggest_int(\"units_second_layer\", 10, 100)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"selu\", \"elu\", \"swish\"])\n",
    "\n",
    "    # Build the Keras model (as per your provided structure)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units_first_layer, activation),\n",
    "        layers.Dense(units_second_layer, activation),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate))\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 14:28:28,613] A new study created in memory with name: no-name-d45157c7-bb0b-4016-8451-21e9b54197d5\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:29,235] Trial 0 finished with value: 0.1570568084716797 and parameters: {'learning_rate': 0.0024363924239892668, 'units_first_layer': 100, 'units_second_layer': 23, 'activation': 'swish'}. Best is trial 0 with value: 0.1570568084716797.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:29,588] Trial 1 finished with value: 0.20315992832183838 and parameters: {'learning_rate': 0.001149381615465511, 'units_first_layer': 21, 'units_second_layer': 62, 'activation': 'selu'}. Best is trial 0 with value: 0.1570568084716797.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:29,941] Trial 2 finished with value: 0.39364394545555115 and parameters: {'learning_rate': 0.00852026753036606, 'units_first_layer': 12, 'units_second_layer': 29, 'activation': 'selu'}. Best is trial 0 with value: 0.1570568084716797.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:30,325] Trial 3 finished with value: 0.5535844564437866 and parameters: {'learning_rate': 1.4429839893521424e-05, 'units_first_layer': 61, 'units_second_layer': 66, 'activation': 'swish'}. Best is trial 0 with value: 0.1570568084716797.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:30,706] Trial 4 finished with value: 0.47057875990867615 and parameters: {'learning_rate': 0.000211972726970716, 'units_first_layer': 34, 'units_second_layer': 98, 'activation': 'swish'}. Best is trial 0 with value: 0.1570568084716797.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:31,058] Trial 5 finished with value: 0.540828287601471 and parameters: {'learning_rate': 1.1738340447919e-05, 'units_first_layer': 17, 'units_second_layer': 40, 'activation': 'elu'}. Best is trial 0 with value: 0.1570568084716797.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:31,413] Trial 6 finished with value: 0.20273299515247345 and parameters: {'learning_rate': 0.003212589120488019, 'units_first_layer': 61, 'units_second_layer': 42, 'activation': 'elu'}. Best is trial 0 with value: 0.1570568084716797.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:31,802] Trial 7 finished with value: 0.18126994371414185 and parameters: {'learning_rate': 0.00197199370646862, 'units_first_layer': 21, 'units_second_layer': 91, 'activation': 'swish'}. Best is trial 0 with value: 0.1570568084716797.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:32,166] Trial 8 finished with value: 0.1499004065990448 and parameters: {'learning_rate': 0.0016348001440932187, 'units_first_layer': 16, 'units_second_layer': 88, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:32,542] Trial 9 finished with value: 0.7138949036598206 and parameters: {'learning_rate': 0.00021461212018378243, 'units_first_layer': 16, 'units_second_layer': 15, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:32,927] Trial 10 finished with value: 1.2699381113052368 and parameters: {'learning_rate': 7.151139125835997e-05, 'units_first_layer': 82, 'units_second_layer': 81, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:33,313] Trial 11 finished with value: 0.318302184343338 and parameters: {'learning_rate': 0.0007397562733690037, 'units_first_layer': 100, 'units_second_layer': 13, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:33,688] Trial 12 finished with value: 0.23526372015476227 and parameters: {'learning_rate': 0.008646780483709426, 'units_first_layer': 42, 'units_second_layer': 76, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:34,071] Trial 13 finished with value: 0.2845626175403595 and parameters: {'learning_rate': 0.0005502376336780821, 'units_first_layer': 84, 'units_second_layer': 49, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:34,469] Trial 14 finished with value: 0.2518729269504547 and parameters: {'learning_rate': 0.0031649150178040156, 'units_first_layer': 45, 'units_second_layer': 34, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:34,834] Trial 15 finished with value: 0.298078715801239 and parameters: {'learning_rate': 0.0017338174565380683, 'units_first_layer': 80, 'units_second_layer': 24, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:35,352] Trial 16 finished with value: 0.29697659611701965 and parameters: {'learning_rate': 8.642578148444623e-05, 'units_first_layer': 100, 'units_second_layer': 55, 'activation': 'selu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:35,716] Trial 17 finished with value: 0.17698045074939728 and parameters: {'learning_rate': 0.004404243537293129, 'units_first_layer': 69, 'units_second_layer': 76, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:36,106] Trial 18 finished with value: 0.23655879497528076 and parameters: {'learning_rate': 0.0004582605077222449, 'units_first_layer': 33, 'units_second_layer': 88, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:36,468] Trial 19 finished with value: 0.3330245316028595 and parameters: {'learning_rate': 0.0011487491394424725, 'units_first_layer': 53, 'units_second_layer': 66, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:36,855] Trial 20 finished with value: 0.17895002663135529 and parameters: {'learning_rate': 0.005619148347466378, 'units_first_layer': 92, 'units_second_layer': 22, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:37,214] Trial 21 finished with value: 0.2371840924024582 and parameters: {'learning_rate': 0.003413644227116139, 'units_first_layer': 71, 'units_second_layer': 77, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:37,574] Trial 22 finished with value: 0.23742131888866425 and parameters: {'learning_rate': 0.004476124458110578, 'units_first_layer': 71, 'units_second_layer': 99, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:37,946] Trial 23 finished with value: 0.15590833127498627 and parameters: {'learning_rate': 0.0017558323125622369, 'units_first_layer': 72, 'units_second_layer': 85, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:38,310] Trial 24 finished with value: 0.1962246298789978 and parameters: {'learning_rate': 0.0018828355752238827, 'units_first_layer': 53, 'units_second_layer': 87, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:38,668] Trial 25 finished with value: 0.2258366495370865 and parameters: {'learning_rate': 0.0010434646080428702, 'units_first_layer': 90, 'units_second_layer': 69, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:39,027] Trial 26 finished with value: 0.3161117434501648 and parameters: {'learning_rate': 0.00030776065807051406, 'units_first_layer': 75, 'units_second_layer': 58, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:39,386] Trial 27 finished with value: 0.31841376423835754 and parameters: {'learning_rate': 0.0018596689851734169, 'units_first_layer': 29, 'units_second_layer': 48, 'activation': 'selu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:39,743] Trial 28 finished with value: 0.31347599625587463 and parameters: {'learning_rate': 0.0006420652925027188, 'units_first_layer': 91, 'units_second_layer': 83, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:40,102] Trial 29 finished with value: 0.3652065694332123 and parameters: {'learning_rate': 0.0008829060488065293, 'units_first_layer': 63, 'units_second_layer': 94, 'activation': 'selu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:40,460] Trial 30 finished with value: 0.1616516262292862 and parameters: {'learning_rate': 0.002400107840555768, 'units_first_layer': 46, 'units_second_layer': 72, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:40,818] Trial 31 finished with value: 0.19080686569213867 and parameters: {'learning_rate': 0.0014757475481118922, 'units_first_layer': 45, 'units_second_layer': 69, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:41,176] Trial 32 finished with value: 0.17291438579559326 and parameters: {'learning_rate': 0.002511986267096885, 'units_first_layer': 28, 'units_second_layer': 83, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:41,537] Trial 33 finished with value: 0.2505062222480774 and parameters: {'learning_rate': 0.006743225395873926, 'units_first_layer': 39, 'units_second_layer': 72, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:41,923] Trial 34 finished with value: 0.1780165582895279 and parameters: {'learning_rate': 0.0013553741862947493, 'units_first_layer': 11, 'units_second_layer': 61, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:42,285] Trial 35 finished with value: 0.18849946558475494 and parameters: {'learning_rate': 0.000370373735448841, 'units_first_layer': 51, 'units_second_layer': 93, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:42,849] Trial 36 finished with value: 0.18024207651615143 and parameters: {'learning_rate': 0.009481666227639882, 'units_first_layer': 65, 'units_second_layer': 86, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:43,215] Trial 37 finished with value: 0.9138442873954773 and parameters: {'learning_rate': 0.002871770980478073, 'units_first_layer': 60, 'units_second_layer': 64, 'activation': 'selu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:43,578] Trial 38 finished with value: 0.6437506079673767 and parameters: {'learning_rate': 0.0001314222056622376, 'units_first_layer': 23, 'units_second_layer': 96, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:43,968] Trial 39 finished with value: 0.19710947573184967 and parameters: {'learning_rate': 0.00522036329878534, 'units_first_layer': 77, 'units_second_layer': 40, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:44,330] Trial 40 finished with value: 0.9076859354972839 and parameters: {'learning_rate': 2.1257935685799356e-05, 'units_first_layer': 58, 'units_second_layer': 81, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:44,691] Trial 41 finished with value: 0.32415086030960083 and parameters: {'learning_rate': 0.002207714588793316, 'units_first_layer': 27, 'units_second_layer': 90, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:45,052] Trial 42 finished with value: 0.23625768721103668 and parameters: {'learning_rate': 0.002880857758586031, 'units_first_layer': 16, 'units_second_layer': 83, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:45,414] Trial 43 finished with value: 0.15953180193901062 and parameters: {'learning_rate': 0.002279991976522635, 'units_first_layer': 22, 'units_second_layer': 73, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:45,777] Trial 44 finished with value: 0.2594752311706543 and parameters: {'learning_rate': 0.0008327121151047737, 'units_first_layer': 22, 'units_second_layer': 73, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:46,137] Trial 45 finished with value: 0.23464088141918182 and parameters: {'learning_rate': 0.004003152523035751, 'units_first_layer': 37, 'units_second_layer': 49, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:46,499] Trial 46 finished with value: 0.24277901649475098 and parameters: {'learning_rate': 0.0065485362411103155, 'units_first_layer': 14, 'units_second_layer': 10, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:46,888] Trial 47 finished with value: 0.19536852836608887 and parameters: {'learning_rate': 0.0012916886586926404, 'units_first_layer': 49, 'units_second_layer': 32, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:47,250] Trial 48 finished with value: 0.1679219752550125 and parameters: {'learning_rate': 0.0016542085605782994, 'units_first_layer': 10, 'units_second_layer': 77, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:47,613] Trial 49 finished with value: 0.25465431809425354 and parameters: {'learning_rate': 0.002343436258495827, 'units_first_layer': 19, 'units_second_layer': 59, 'activation': 'elu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:48,001] Trial 50 finished with value: 0.20970183610916138 and parameters: {'learning_rate': 0.0005186137712592594, 'units_first_layer': 86, 'units_second_layer': 19, 'activation': 'swish'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:48,366] Trial 51 finished with value: 0.2798910439014435 and parameters: {'learning_rate': 0.0015166771111357331, 'units_first_layer': 13, 'units_second_layer': 78, 'activation': 'relu'}. Best is trial 8 with value: 0.1499004065990448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:48,741] Trial 52 finished with value: 0.1298944354057312 and parameters: {'learning_rate': 0.003655316713200898, 'units_first_layer': 11, 'units_second_layer': 71, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:49,116] Trial 53 finished with value: 0.3680075705051422 and parameters: {'learning_rate': 0.0038859420128696106, 'units_first_layer': 96, 'units_second_layer': 72, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:49,483] Trial 54 finished with value: 0.2087654024362564 and parameters: {'learning_rate': 0.002292792024490839, 'units_first_layer': 25, 'units_second_layer': 68, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:49,857] Trial 55 finished with value: 0.2794265151023865 and parameters: {'learning_rate': 0.0010539840464372583, 'units_first_layer': 32, 'units_second_layer': 44, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:50,224] Trial 56 finished with value: 0.1806965470314026 and parameters: {'learning_rate': 0.0032323860061985363, 'units_first_layer': 18, 'units_second_layer': 73, 'activation': 'selu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:50,593] Trial 57 finished with value: 0.13909585773944855 and parameters: {'learning_rate': 0.007291078333006728, 'units_first_layer': 14, 'units_second_layer': 64, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:50,960] Trial 58 finished with value: 0.1764945536851883 and parameters: {'learning_rate': 0.007470424511181449, 'units_first_layer': 19, 'units_second_layer': 55, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:51,535] Trial 59 finished with value: 0.21919827163219452 and parameters: {'learning_rate': 0.005331218134517027, 'units_first_layer': 15, 'units_second_layer': 65, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:51,917] Trial 60 finished with value: 0.2752823531627655 and parameters: {'learning_rate': 0.009961609153578613, 'units_first_layer': 10, 'units_second_layer': 80, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:52,301] Trial 61 finished with value: 0.2460985779762268 and parameters: {'learning_rate': 0.0044294763311374, 'units_first_layer': 22, 'units_second_layer': 62, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:52,667] Trial 62 finished with value: 0.24575524032115936 and parameters: {'learning_rate': 0.0032723161992431428, 'units_first_layer': 67, 'units_second_layer': 74, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:53,034] Trial 63 finished with value: 0.37716320157051086 and parameters: {'learning_rate': 0.0019741676830685993, 'units_first_layer': 13, 'units_second_layer': 85, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:53,427] Trial 64 finished with value: 0.21714544296264648 and parameters: {'learning_rate': 0.005883806534776842, 'units_first_layer': 25, 'units_second_layer': 70, 'activation': 'swish'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:53,791] Trial 65 finished with value: 0.19146239757537842 and parameters: {'learning_rate': 0.0075306599312043926, 'units_first_layer': 56, 'units_second_layer': 90, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:54,158] Trial 66 finished with value: 0.15322990715503693 and parameters: {'learning_rate': 0.002611016879206757, 'units_first_layer': 30, 'units_second_layer': 100, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:54,528] Trial 67 finished with value: 0.18125607073307037 and parameters: {'learning_rate': 0.0037938210858901806, 'units_first_layer': 31, 'units_second_layer': 96, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:54,894] Trial 68 finished with value: 0.17941059172153473 and parameters: {'learning_rate': 0.004753459747257032, 'units_first_layer': 35, 'units_second_layer': 93, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:55,269] Trial 69 finished with value: 0.25788792967796326 and parameters: {'learning_rate': 3.6313108063396464e-05, 'units_first_layer': 19, 'units_second_layer': 99, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:55,691] Trial 70 finished with value: 0.41480568051338196 and parameters: {'learning_rate': 0.0009084936077322993, 'units_first_layer': 25, 'units_second_layer': 89, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:56,074] Trial 71 finished with value: 0.24344180524349213 and parameters: {'learning_rate': 0.0023376561650710454, 'units_first_layer': 43, 'units_second_layer': 66, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:56,467] Trial 72 finished with value: 0.3033964931964874 and parameters: {'learning_rate': 0.0027064185363560767, 'units_first_layer': 17, 'units_second_layer': 58, 'activation': 'selu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:56,870] Trial 73 finished with value: 0.16440902650356293 and parameters: {'learning_rate': 0.0018113279870394835, 'units_first_layer': 87, 'units_second_layer': 100, 'activation': 'swish'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:57,236] Trial 74 finished with value: 0.3550005853176117 and parameters: {'learning_rate': 0.0011419661353808284, 'units_first_layer': 96, 'units_second_layer': 78, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:57,631] Trial 75 finished with value: 0.14929120242595673 and parameters: {'learning_rate': 0.0006720139327217371, 'units_first_layer': 40, 'units_second_layer': 75, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:58,031] Trial 76 finished with value: 0.18964523077011108 and parameters: {'learning_rate': 0.0007456176203993374, 'units_first_layer': 29, 'units_second_layer': 85, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:58,427] Trial 77 finished with value: 0.219201922416687 and parameters: {'learning_rate': 0.0002544865094246641, 'units_first_layer': 41, 'units_second_layer': 80, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:58,856] Trial 78 finished with value: 0.3425251543521881 and parameters: {'learning_rate': 0.0014562061223847669, 'units_first_layer': 21, 'units_second_layer': 96, 'activation': 'swish'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:59,274] Trial 79 finished with value: 0.20774026215076447 and parameters: {'learning_rate': 0.0006362090219314882, 'units_first_layer': 35, 'units_second_layer': 76, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:28:59,647] Trial 80 finished with value: 0.26560500264167786 and parameters: {'learning_rate': 0.00040219774636482647, 'units_first_layer': 80, 'units_second_layer': 53, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:00,024] Trial 81 finished with value: 0.15866748988628387 and parameters: {'learning_rate': 0.002709110137070626, 'units_first_layer': 47, 'units_second_layer': 70, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:00,399] Trial 82 finished with value: 0.2046290785074234 and parameters: {'learning_rate': 0.0027838696820055527, 'units_first_layer': 49, 'units_second_layer': 68, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:00,764] Trial 83 finished with value: 0.2298055738210678 and parameters: {'learning_rate': 0.0035682611161935514, 'units_first_layer': 46, 'units_second_layer': 70, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:01,127] Trial 84 finished with value: 0.28861722350120544 and parameters: {'learning_rate': 0.00194137818410312, 'units_first_layer': 37, 'units_second_layer': 63, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:01,733] Trial 85 finished with value: 0.8124930262565613 and parameters: {'learning_rate': 0.00015523496503720442, 'units_first_layer': 12, 'units_second_layer': 82, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:02,106] Trial 86 finished with value: 0.32877662777900696 and parameters: {'learning_rate': 0.001262605074388453, 'units_first_layer': 15, 'units_second_layer': 60, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:02,489] Trial 87 finished with value: 0.4094292223453522 and parameters: {'learning_rate': 0.0017335902401495894, 'units_first_layer': 20, 'units_second_layer': 79, 'activation': 'selu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:02,866] Trial 88 finished with value: 0.22254030406475067 and parameters: {'learning_rate': 0.002150404729087053, 'units_first_layer': 39, 'units_second_layer': 67, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:03,260] Trial 89 finished with value: 0.19990313053131104 and parameters: {'learning_rate': 0.0029568426232296162, 'units_first_layer': 27, 'units_second_layer': 29, 'activation': 'swish'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:03,628] Trial 90 finished with value: 0.17817866802215576 and parameters: {'learning_rate': 0.0009554123669375035, 'units_first_layer': 73, 'units_second_layer': 75, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:03,999] Trial 91 finished with value: 0.209080770611763 and parameters: {'learning_rate': 0.002498476471535242, 'units_first_layer': 53, 'units_second_layer': 71, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:04,369] Trial 92 finished with value: 0.26522812247276306 and parameters: {'learning_rate': 0.004104261844540033, 'units_first_layer': 48, 'units_second_layer': 64, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:04,747] Trial 93 finished with value: 0.17701421678066254 and parameters: {'learning_rate': 0.006169511036951794, 'units_first_layer': 42, 'units_second_layer': 87, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:05,140] Trial 94 finished with value: 0.1809375286102295 and parameters: {'learning_rate': 0.0016112164850117135, 'units_first_layer': 46, 'units_second_layer': 73, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:05,527] Trial 95 finished with value: 0.2214425653219223 and parameters: {'learning_rate': 0.004667248951409616, 'units_first_layer': 51, 'units_second_layer': 93, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:05,917] Trial 96 finished with value: 0.191789448261261 and parameters: {'learning_rate': 0.0032146574797959223, 'units_first_layer': 56, 'units_second_layer': 75, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:06,292] Trial 97 finished with value: 0.2085779756307602 and parameters: {'learning_rate': 0.0013771477879071946, 'units_first_layer': 31, 'units_second_layer': 71, 'activation': 'relu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:06,666] Trial 98 finished with value: 1.043689250946045 and parameters: {'learning_rate': 0.00806109782913006, 'units_first_layer': 44, 'units_second_layer': 67, 'activation': 'elu'}. Best is trial 52 with value: 0.1298944354057312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-01-21 14:29:07,067] Trial 99 finished with value: 0.1611642986536026 and parameters: {'learning_rate': 0.002092065271434113, 'units_first_layer': 17, 'units_second_layer': 57, 'activation': 'swish'}. Best is trial 52 with value: 0.1298944354057312.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " Value of loss: 0.1298944354057312\n",
      " Best hyperparameters: {'learning_rate': 0.003655316713200898, 'units_first_layer': 11, 'units_second_layer': 71, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\" Value of loss:\", trial.value)\n",
    "print(\" Best hyperparameters:\", trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 14:30:54,487] A new study created in memory with name: no-name-1ed4db4e-fb36-4abe-8a62-98d25b500370\n",
      "[I 2024-01-21 14:30:54,799] Trial 0 finished with value: 0.19664347171783447 and parameters: {'learning_rate': 0.0037614400386799607, 'units_first_layer': 53, 'units_second_layer': 51, 'activation': 'relu'}. Best is trial 0 with value: 0.19664347171783447.\n",
      "[I 2024-01-21 14:30:55,096] Trial 1 finished with value: 1.001639485359192 and parameters: {'learning_rate': 0.00010417996041379952, 'units_first_layer': 63, 'units_second_layer': 65, 'activation': 'elu'}. Best is trial 0 with value: 0.19664347171783447.\n",
      "[I 2024-01-21 14:30:55,384] Trial 2 finished with value: 0.2785108983516693 and parameters: {'learning_rate': 0.006262402126916757, 'units_first_layer': 38, 'units_second_layer': 50, 'activation': 'relu'}. Best is trial 0 with value: 0.19664347171783447.\n",
      "[I 2024-01-21 14:30:55,693] Trial 3 finished with value: 0.18453969061374664 and parameters: {'learning_rate': 0.00667129938464703, 'units_first_layer': 43, 'units_second_layer': 97, 'activation': 'swish'}. Best is trial 3 with value: 0.18453969061374664.\n",
      "[I 2024-01-21 14:30:56,002] Trial 4 finished with value: 0.48912927508354187 and parameters: {'learning_rate': 2.012869592821866e-05, 'units_first_layer': 10, 'units_second_layer': 77, 'activation': 'swish'}. Best is trial 3 with value: 0.18453969061374664.\n",
      "[I 2024-01-21 14:30:56,312] Trial 5 finished with value: 0.18837545812129974 and parameters: {'learning_rate': 0.0011819073864645104, 'units_first_layer': 100, 'units_second_layer': 35, 'activation': 'swish'}. Best is trial 3 with value: 0.18453969061374664.\n",
      "[I 2024-01-21 14:30:56,601] Trial 6 finished with value: 0.902536153793335 and parameters: {'learning_rate': 0.008113474021527931, 'units_first_layer': 28, 'units_second_layer': 78, 'activation': 'elu'}. Best is trial 3 with value: 0.18453969061374664.\n",
      "[I 2024-01-21 14:30:56,899] Trial 7 finished with value: 0.341630220413208 and parameters: {'learning_rate': 0.00010229465965679041, 'units_first_layer': 71, 'units_second_layer': 69, 'activation': 'relu'}. Best is trial 3 with value: 0.18453969061374664.\n",
      "[I 2024-01-21 14:30:57,187] Trial 8 finished with value: 0.8273541927337646 and parameters: {'learning_rate': 0.00013600482515236937, 'units_first_layer': 10, 'units_second_layer': 30, 'activation': 'selu'}. Best is trial 3 with value: 0.18453969061374664.\n",
      "[I 2024-01-21 14:30:57,484] Trial 9 finished with value: 0.31621789932250977 and parameters: {'learning_rate': 0.00035416847110919465, 'units_first_layer': 28, 'units_second_layer': 55, 'activation': 'elu'}. Best is trial 3 with value: 0.18453969061374664.\n",
      "[I 2024-01-21 14:30:57,826] Trial 10 finished with value: 0.1943085789680481 and parameters: {'learning_rate': 0.0013059199492697529, 'units_first_layer': 84, 'units_second_layer': 100, 'activation': 'swish'}. Best is trial 3 with value: 0.18453969061374664.\n",
      "[I 2024-01-21 14:30:58,170] Trial 11 finished with value: 0.18111006915569305 and parameters: {'learning_rate': 0.0015068481227974199, 'units_first_layer': 98, 'units_second_layer': 11, 'activation': 'swish'}. Best is trial 11 with value: 0.18111006915569305.\n",
      "[I 2024-01-21 14:30:58,492] Trial 12 finished with value: 0.19399893283843994 and parameters: {'learning_rate': 0.0021504603565219655, 'units_first_layer': 49, 'units_second_layer': 100, 'activation': 'swish'}. Best is trial 11 with value: 0.18111006915569305.\n",
      "[I 2024-01-21 14:30:58,808] Trial 13 finished with value: 0.22043311595916748 and parameters: {'learning_rate': 0.0005129801930246955, 'units_first_layer': 83, 'units_second_layer': 11, 'activation': 'swish'}. Best is trial 11 with value: 0.18111006915569305.\n",
      "[I 2024-01-21 14:30:59,115] Trial 14 finished with value: 0.17455828189849854 and parameters: {'learning_rate': 0.009969405288445445, 'units_first_layer': 93, 'units_second_layer': 11, 'activation': 'selu'}. Best is trial 14 with value: 0.17455828189849854.\n",
      "[I 2024-01-21 14:30:59,409] Trial 15 finished with value: 0.9983005523681641 and parameters: {'learning_rate': 0.002243945194172693, 'units_first_layer': 100, 'units_second_layer': 10, 'activation': 'selu'}. Best is trial 14 with value: 0.17455828189849854.\n",
      "[I 2024-01-21 14:30:59,707] Trial 16 finished with value: 0.29641956090927124 and parameters: {'learning_rate': 0.0007842036424037317, 'units_first_layer': 85, 'units_second_layer': 23, 'activation': 'selu'}. Best is trial 14 with value: 0.17455828189849854.\n",
      "[I 2024-01-21 14:31:00,004] Trial 17 finished with value: 0.42618414759635925 and parameters: {'learning_rate': 0.003101660031036845, 'units_first_layer': 71, 'units_second_layer': 22, 'activation': 'selu'}. Best is trial 14 with value: 0.17455828189849854.\n",
      "[I 2024-01-21 14:31:00,301] Trial 18 finished with value: 0.8486614227294922 and parameters: {'learning_rate': 0.00931127878954249, 'units_first_layer': 92, 'units_second_layer': 34, 'activation': 'selu'}. Best is trial 14 with value: 0.17455828189849854.\n",
      "[I 2024-01-21 14:31:00,592] Trial 19 finished with value: 2.5779645442962646 and parameters: {'learning_rate': 1.0455386815143937e-05, 'units_first_layer': 75, 'units_second_layer': 40, 'activation': 'selu'}. Best is trial 14 with value: 0.17455828189849854.\n",
      "[I 2024-01-21 14:31:00,910] Trial 20 finished with value: 0.25333938002586365 and parameters: {'learning_rate': 0.00016425281801744494, 'units_first_layer': 92, 'units_second_layer': 19, 'activation': 'swish'}. Best is trial 14 with value: 0.17455828189849854.\n",
      "[I 2024-01-21 14:31:01,552] Trial 21 finished with value: 0.19604001939296722 and parameters: {'learning_rate': 0.004759953578201346, 'units_first_layer': 41, 'units_second_layer': 83, 'activation': 'swish'}. Best is trial 14 with value: 0.17455828189849854.\n",
      "[I 2024-01-21 14:31:01,902] Trial 22 finished with value: 0.16822285950183868 and parameters: {'learning_rate': 0.009563929867799201, 'units_first_layer': 64, 'units_second_layer': 91, 'activation': 'swish'}. Best is trial 22 with value: 0.16822285950183868.\n",
      "[I 2024-01-21 14:31:02,238] Trial 23 finished with value: 0.23196683824062347 and parameters: {'learning_rate': 0.00978606334201726, 'units_first_layer': 62, 'units_second_layer': 44, 'activation': 'swish'}. Best is trial 22 with value: 0.16822285950183868.\n",
      "[I 2024-01-21 14:31:02,572] Trial 24 finished with value: 0.16727213561534882 and parameters: {'learning_rate': 0.001557156252591776, 'units_first_layer': 91, 'units_second_layer': 17, 'activation': 'swish'}. Best is trial 24 with value: 0.16727213561534882.\n",
      "[I 2024-01-21 14:31:02,875] Trial 25 finished with value: 0.21823197603225708 and parameters: {'learning_rate': 0.002936783925816784, 'units_first_layer': 76, 'units_second_layer': 19, 'activation': 'selu'}. Best is trial 24 with value: 0.16727213561534882.\n",
      "[I 2024-01-21 14:31:03,186] Trial 26 finished with value: 0.17954415082931519 and parameters: {'learning_rate': 0.004335592432296583, 'units_first_layer': 63, 'units_second_layer': 89, 'activation': 'relu'}. Best is trial 24 with value: 0.16727213561534882.\n",
      "[I 2024-01-21 14:31:03,510] Trial 27 finished with value: 0.2182741016149521 and parameters: {'learning_rate': 4.963214919718097e-05, 'units_first_layer': 91, 'units_second_layer': 28, 'activation': 'elu'}. Best is trial 24 with value: 0.16727213561534882.\n",
      "[I 2024-01-21 14:31:03,854] Trial 28 finished with value: 0.2397649735212326 and parameters: {'learning_rate': 0.0007618402140749366, 'units_first_layer': 81, 'units_second_layer': 60, 'activation': 'swish'}. Best is trial 24 with value: 0.16727213561534882.\n",
      "[I 2024-01-21 14:31:04,164] Trial 29 finished with value: 0.1595747023820877 and parameters: {'learning_rate': 0.004415396772278371, 'units_first_layer': 56, 'units_second_layer': 47, 'activation': 'relu'}. Best is trial 29 with value: 0.1595747023820877.\n",
      "[I 2024-01-21 14:31:04,471] Trial 30 finished with value: 0.13989530503749847 and parameters: {'learning_rate': 0.004339952696972031, 'units_first_layer': 56, 'units_second_layer': 47, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:04,781] Trial 31 finished with value: 0.20321853458881378 and parameters: {'learning_rate': 0.004459029455128777, 'units_first_layer': 55, 'units_second_layer': 49, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:05,091] Trial 32 finished with value: 0.18448662757873535 and parameters: {'learning_rate': 0.002021870849372061, 'units_first_layer': 49, 'units_second_layer': 60, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:05,388] Trial 33 finished with value: 0.18721307814121246 and parameters: {'learning_rate': 0.005502512693972233, 'units_first_layer': 59, 'units_second_layer': 43, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:05,683] Trial 34 finished with value: 0.21231676638126373 and parameters: {'learning_rate': 0.003079349502258842, 'units_first_layer': 67, 'units_second_layer': 66, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:05,976] Trial 35 finished with value: 0.25478753447532654 and parameters: {'learning_rate': 0.006031266748860397, 'units_first_layer': 48, 'units_second_layer': 73, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:06,269] Trial 36 finished with value: 0.17075319588184357 and parameters: {'learning_rate': 0.003477466855495131, 'units_first_layer': 31, 'units_second_layer': 49, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:06,560] Trial 37 finished with value: 0.37092867493629456 and parameters: {'learning_rate': 0.0007745222923837988, 'units_first_layer': 55, 'units_second_layer': 93, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:06,852] Trial 38 finished with value: 0.20901821553707123 and parameters: {'learning_rate': 0.0063051020910487995, 'units_first_layer': 34, 'units_second_layer': 56, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:07,146] Trial 39 finished with value: 0.2977321445941925 and parameters: {'learning_rate': 0.001762599581638958, 'units_first_layer': 20, 'units_second_layer': 39, 'activation': 'elu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:07,477] Trial 40 finished with value: 0.3854764997959137 and parameters: {'learning_rate': 0.0010040988354962804, 'units_first_layer': 44, 'units_second_layer': 85, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:07,774] Trial 41 finished with value: 0.23788225650787354 and parameters: {'learning_rate': 0.0030623983017552254, 'units_first_layer': 59, 'units_second_layer': 48, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:08,088] Trial 42 finished with value: 0.1677478700876236 and parameters: {'learning_rate': 0.00686319589902768, 'units_first_layer': 35, 'units_second_layer': 53, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:08,385] Trial 43 finished with value: 0.1830834299325943 and parameters: {'learning_rate': 0.007625064556461175, 'units_first_layer': 21, 'units_second_layer': 60, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:08,698] Trial 44 finished with value: 0.18161731958389282 and parameters: {'learning_rate': 0.00656522303374623, 'units_first_layer': 67, 'units_second_layer': 71, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:09,052] Trial 45 finished with value: 0.2210908681154251 and parameters: {'learning_rate': 0.004078913572197592, 'units_first_layer': 40, 'units_second_layer': 34, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:09,357] Trial 46 finished with value: 0.2312345653772354 and parameters: {'learning_rate': 0.00240646387605165, 'units_first_layer': 50, 'units_second_layer': 65, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:09,651] Trial 47 finished with value: 0.230865940451622 and parameters: {'learning_rate': 0.0014540304852003058, 'units_first_layer': 36, 'units_second_layer': 54, 'activation': 'elu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:09,971] Trial 48 finished with value: 0.21525585651397705 and parameters: {'learning_rate': 0.0004351782294731552, 'units_first_layer': 45, 'units_second_layer': 77, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:10,266] Trial 49 finished with value: 0.29889336228370667 and parameters: {'learning_rate': 0.00023880677538264632, 'units_first_layer': 59, 'units_second_layer': 44, 'activation': 'relu'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:10,586] Trial 50 finished with value: 0.15685699880123138 and parameters: {'learning_rate': 0.006772998687290834, 'units_first_layer': 21, 'units_second_layer': 55, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:10,911] Trial 51 finished with value: 0.29838111996650696 and parameters: {'learning_rate': 0.007662689902682359, 'units_first_layer': 16, 'units_second_layer': 55, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:11,231] Trial 52 finished with value: 0.18620465695858002 and parameters: {'learning_rate': 0.005307135780381834, 'units_first_layer': 25, 'units_second_layer': 53, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:11,572] Trial 53 finished with value: 0.20277772843837738 and parameters: {'learning_rate': 0.008152022310688138, 'units_first_layer': 13, 'units_second_layer': 38, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:11,910] Trial 54 finished with value: 0.20079700648784637 and parameters: {'learning_rate': 0.00368373796218597, 'units_first_layer': 52, 'units_second_layer': 64, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:12,242] Trial 55 finished with value: 0.1678391695022583 and parameters: {'learning_rate': 0.002367676592743795, 'units_first_layer': 32, 'units_second_layer': 46, 'activation': 'swish'}. Best is trial 30 with value: 0.13989530503749847.\n",
      "[I 2024-01-21 14:31:12,570] Trial 56 finished with value: 0.13272441923618317 and parameters: {'learning_rate': 0.002691225139497515, 'units_first_layer': 25, 'units_second_layer': 29, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:12,863] Trial 57 finished with value: 0.3461761176586151 and parameters: {'learning_rate': 0.001064690647695038, 'units_first_layer': 29, 'units_second_layer': 18, 'activation': 'relu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:13,182] Trial 58 finished with value: 0.20308129489421844 and parameters: {'learning_rate': 0.0027253853214126585, 'units_first_layer': 25, 'units_second_layer': 29, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:13,474] Trial 59 finished with value: 0.20686256885528564 and parameters: {'learning_rate': 0.001736694613622346, 'units_first_layer': 18, 'units_second_layer': 15, 'activation': 'elu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:13,790] Trial 60 finished with value: 0.6437543630599976 and parameters: {'learning_rate': 4.1681890867620656e-05, 'units_first_layer': 25, 'units_second_layer': 32, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:14,106] Trial 61 finished with value: 0.1714521199464798 and parameters: {'learning_rate': 0.002320674648247707, 'units_first_layer': 21, 'units_second_layer': 46, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:14,424] Trial 62 finished with value: 0.16546562314033508 and parameters: {'learning_rate': 0.00499918763596188, 'units_first_layer': 33, 'units_second_layer': 24, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:14,741] Trial 63 finished with value: 0.26677075028419495 and parameters: {'learning_rate': 0.004473511872283411, 'units_first_layer': 36, 'units_second_layer': 25, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:15,062] Trial 64 finished with value: 0.17453360557556152 and parameters: {'learning_rate': 0.0052904826978346494, 'units_first_layer': 13, 'units_second_layer': 14, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:15,378] Trial 65 finished with value: 0.20714861154556274 and parameters: {'learning_rate': 0.0038448101461966066, 'units_first_layer': 28, 'units_second_layer': 25, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:15,671] Trial 66 finished with value: 0.17533224821090698 and parameters: {'learning_rate': 0.007425524948742114, 'units_first_layer': 39, 'units_second_layer': 52, 'activation': 'relu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:16,359] Trial 67 finished with value: 0.1722457855939865 and parameters: {'learning_rate': 0.00504659255324751, 'units_first_layer': 88, 'units_second_layer': 36, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:16,672] Trial 68 finished with value: 0.2542419135570526 and parameters: {'learning_rate': 0.0017995025847493175, 'units_first_layer': 78, 'units_second_layer': 41, 'activation': 'relu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:16,986] Trial 69 finished with value: 0.6587103009223938 and parameters: {'learning_rate': 0.0034933283573189014, 'units_first_layer': 42, 'units_second_layer': 22, 'activation': 'selu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:17,315] Trial 70 finished with value: 0.2358808070421219 and parameters: {'learning_rate': 0.0006065374824539474, 'units_first_layer': 23, 'units_second_layer': 57, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:17,645] Trial 71 finished with value: 0.249702587723732 and parameters: {'learning_rate': 0.0012127869641335785, 'units_first_layer': 32, 'units_second_layer': 46, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:17,975] Trial 72 finished with value: 0.1760677844285965 and parameters: {'learning_rate': 0.0028890695985644486, 'units_first_layer': 32, 'units_second_layer': 51, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:18,299] Trial 73 finished with value: 0.16009823977947235 and parameters: {'learning_rate': 0.006102236319177172, 'units_first_layer': 37, 'units_second_layer': 58, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:18,621] Trial 74 finished with value: 0.1504715234041214 and parameters: {'learning_rate': 0.006442255062921023, 'units_first_layer': 46, 'units_second_layer': 58, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:18,945] Trial 75 finished with value: 0.17045404016971588 and parameters: {'learning_rate': 0.005554028912910602, 'units_first_layer': 96, 'units_second_layer': 58, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:19,266] Trial 76 finished with value: 0.2755398452281952 and parameters: {'learning_rate': 0.008980106907950303, 'units_first_layer': 46, 'units_second_layer': 62, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:19,590] Trial 77 finished with value: 0.2307947427034378 and parameters: {'learning_rate': 0.0042553365603785155, 'units_first_layer': 53, 'units_second_layer': 68, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:19,912] Trial 78 finished with value: 0.21517817676067352 and parameters: {'learning_rate': 0.006885756311396873, 'units_first_layer': 72, 'units_second_layer': 26, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:20,234] Trial 79 finished with value: 0.2602919638156891 and parameters: {'learning_rate': 0.006006939695161772, 'units_first_layer': 57, 'units_second_layer': 16, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:20,528] Trial 80 finished with value: 0.3089677095413208 and parameters: {'learning_rate': 0.009869666492364147, 'units_first_layer': 38, 'units_second_layer': 22, 'activation': 'elu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:20,824] Trial 81 finished with value: 0.1772373467683792 and parameters: {'learning_rate': 0.007185330284917579, 'units_first_layer': 36, 'units_second_layer': 58, 'activation': 'relu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:21,119] Trial 82 finished with value: 0.19209252297878265 and parameters: {'learning_rate': 0.00467641351787117, 'units_first_layer': 27, 'units_second_layer': 51, 'activation': 'relu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:21,439] Trial 83 finished with value: 0.2241583615541458 and parameters: {'learning_rate': 0.0034986446935564835, 'units_first_layer': 42, 'units_second_layer': 62, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:21,733] Trial 84 finished with value: 0.20637233555316925 and parameters: {'learning_rate': 0.008441806813436998, 'units_first_layer': 47, 'units_second_layer': 54, 'activation': 'relu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:22,053] Trial 85 finished with value: 0.16434602439403534 and parameters: {'learning_rate': 0.006058852973793152, 'units_first_layer': 30, 'units_second_layer': 49, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:22,373] Trial 86 finished with value: 0.14780758321285248 and parameters: {'learning_rate': 0.0061383472338635775, 'units_first_layer': 30, 'units_second_layer': 31, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:22,695] Trial 87 finished with value: 0.2797744572162628 and parameters: {'learning_rate': 0.0061633637609121595, 'units_first_layer': 31, 'units_second_layer': 31, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:23,020] Trial 88 finished with value: 0.20088888704776764 and parameters: {'learning_rate': 0.005010712940367306, 'units_first_layer': 51, 'units_second_layer': 42, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:23,314] Trial 89 finished with value: 0.1757514327764511 and parameters: {'learning_rate': 0.002655432159784499, 'units_first_layer': 23, 'units_second_layer': 37, 'activation': 'selu'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:23,633] Trial 90 finished with value: 0.17227549850940704 and parameters: {'learning_rate': 0.0040640571980301585, 'units_first_layer': 34, 'units_second_layer': 28, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:23,952] Trial 91 finished with value: 0.17213983833789825 and parameters: {'learning_rate': 0.0034622322683509543, 'units_first_layer': 27, 'units_second_layer': 49, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:24,274] Trial 92 finished with value: 0.15239952504634857 and parameters: {'learning_rate': 0.005867812710225333, 'units_first_layer': 29, 'units_second_layer': 20, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:24,592] Trial 93 finished with value: 0.166386678814888 and parameters: {'learning_rate': 0.006206296519721408, 'units_first_layer': 30, 'units_second_layer': 13, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:24,913] Trial 94 finished with value: 0.24150778353214264 and parameters: {'learning_rate': 0.007942255098508322, 'units_first_layer': 18, 'units_second_layer': 20, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:25,230] Trial 95 finished with value: 0.19760651886463165 and parameters: {'learning_rate': 0.004715918203277749, 'units_first_layer': 56, 'units_second_layer': 32, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:25,550] Trial 96 finished with value: 0.2190793752670288 and parameters: {'learning_rate': 0.005730216973908246, 'units_first_layer': 38, 'units_second_layer': 47, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:25,869] Trial 97 finished with value: 0.1764710545539856 and parameters: {'learning_rate': 0.0085432039189138, 'units_first_layer': 61, 'units_second_layer': 62, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:26,188] Trial 98 finished with value: 0.2478393316268921 and parameters: {'learning_rate': 7.301088797145804e-05, 'units_first_layer': 23, 'units_second_layer': 27, 'activation': 'swish'}. Best is trial 56 with value: 0.13272441923618317.\n",
      "[I 2024-01-21 14:31:26,481] Trial 99 finished with value: 0.2215535044670105 and parameters: {'learning_rate': 0.007056879371395575, 'units_first_layer': 26, 'units_second_layer': 35, 'activation': 'elu'}. Best is trial 56 with value: 0.13272441923618317.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " Value of loss: 0.13272441923618317\n",
      " Best hyperparameters: {'learning_rate': 0.002691225139497515, 'units_first_layer': 25, 'units_second_layer': 29, 'activation': 'swish'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\" Value of loss:\", trial.value)\n",
    "print(\" Best hyperparameters:\", trial.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
